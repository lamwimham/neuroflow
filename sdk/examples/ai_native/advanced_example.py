"""
AI Native Agent é«˜çº§ç¤ºä¾‹

å±•ç¤ºé«˜çº§åŠŸèƒ½:
1. å¤šå·¥å…·åä½œ
2. è®°å¿†ç®¡ç†
3. å¯¹è¯å†å²
4. å¤æ‚ä»»åŠ¡å¤„ç†

è¿è¡Œ:
    python examples/ai_native/advanced_example.py
"""

import asyncio
import os
from neuroflow import AINativeAgent, LLMConfig


async def demo_multi_tool():
    """æ¼”ç¤ºå¤šå·¥å…·åä½œ"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 1: å¤šå·¥å…·åä½œ")
    print("="*60 + "\n")
    
    agent = AINativeAgent(
        name="data_processor",
        description="æ•°æ®å¤„ç†åŠ©æ‰‹",
        llm_config=LLMConfig(
            provider="openai",
            model="gpt-4",
        ) if os.getenv("OPENAI_API_KEY") else None,
    )
    
    @agent.tool(name="fetch_data", description="è·å–æ¨¡æ‹Ÿæ•°æ®")
    async def fetch_data(source: str) -> dict:
        """ä»æ•°æ®æºè·å–æ•°æ®"""
        return {
            "source": source,
            "data": [1, 2, 3, 4, 5],
            "timestamp": "2024-01-01",
        }
    
    @agent.tool(name="calculate_stats", description="è®¡ç®—ç»Ÿè®¡æ•°æ®")
    async def calculate_stats(numbers: list) -> dict:
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        if not numbers:
            return {"error": "Empty list"}
        return {
            "count": len(numbers),
            "sum": sum(numbers),
            "average": sum(numbers) / len(numbers),
            "min": min(numbers),
            "max": max(numbers),
        }
    
    @agent.tool(name="format_report", description="æ ¼å¼åŒ–æŠ¥å‘Š")
    async def format_report(title: str, data: dict) -> str:
        """æ ¼å¼åŒ–æŠ¥å‘Š"""
        lines = [f"# {title}", ""]
        for key, value in data.items():
            lines.append(f"- **{key}**: {value}")
        return "\n".join(lines)
    
    print(f"å·²æ³¨å†Œå·¥å…·ï¼š{agent.list_available_tools()}")
    
    # æµ‹è¯•ï¼šå¤„ç†æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š
    if os.getenv("OPENAI_API_KEY"):
        result = await agent.handle(
            "è¯·å¸®æˆ‘è·å– data_source_A çš„æ•°æ®ï¼Œè®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼Œç„¶åç”Ÿæˆä¸€ä»½æŠ¥å‘Š"
        )
        print(f"\nç”¨æˆ·ï¼šè¯·å¸®æˆ‘è·å– data_source_A çš„æ•°æ®ï¼Œè®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼Œç„¶åç”Ÿæˆä¸€ä»½æŠ¥å‘Š")
        print(f"\nåŠ©æ‰‹ï¼š{result['response']}")
        print(f"\nä½¿ç”¨çš„å·¥å…·ï¼š{len(result['tool_results'])} ä¸ª")
        for tr in result['tool_results']:
            print(f"  - {tr['tool']}: {'âœ“' if tr['success'] else 'âœ—'}")
    else:
        print("âš ï¸  éœ€è¦ OPENAI_API_KEY æ‰èƒ½è¿è¡Œæ­¤ç¤ºä¾‹")
        # æ¼”ç¤ºæ‰‹åŠ¨è°ƒç”¨
        data = await agent.execute_tool("fetch_data", source="data_source_A")
        print(f"\nfetch_data ç»“æœï¼š{data}")
        
        stats = await agent.execute_tool("calculate_stats", numbers=data["data"])
        print(f"calculate_stats ç»“æœï¼š{stats}")
        
        report = await agent.execute_tool(
            "format_report", 
            title="æ•°æ®ç»Ÿè®¡æŠ¥å‘Š",
            data=stats
        )
        print(f"\nç”Ÿæˆçš„æŠ¥å‘Š:\n{report}")


async def demo_memory():
    """æ¼”ç¤ºè®°å¿†ç®¡ç†"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 2: è®°å¿†ç®¡ç†")
    print("="*60 + "\n")
    
    agent = AINativeAgent(
        name="memory_assistant",
        description="è®°å¿†åŠ©æ‰‹",
        llm_config=LLMConfig(
            provider="openai",
            model="gpt-4",
        ) if os.getenv("OPENAI_API_KEY") else None,
    )
    
    # å­˜å‚¨è®°å¿†
    agent.store_memory("user_name", "å¼ ä¸‰", tags=["user", "profile"])
    agent.store_memory("user_preference", "å–œæ¬¢ç®€æ´çš„å›ç­”", tags=["user", "preference"])
    agent.store_memory("project_name", "NeuroFlow", tags=["project"])
    
    print("å·²å­˜å‚¨è®°å¿†:")
    print(f"  - user_name: {agent.retrieve_memory('user_name')}")
    print(f"  - user_preference: {agent.retrieve_memory('user_preference')}")
    print(f"  - project_name: {agent.retrieve_memory('project_name')}")
    
    # æœç´¢è®°å¿†
    user_memories = agent.search_memories(tags=["user"])
    print(f"\nç”¨æˆ·ç›¸å…³è®°å¿†ï¼š{user_memories}")
    
    # åœ¨å¯¹è¯ä¸­ä½¿ç”¨è®°å¿†
    if os.getenv("OPENAI_API_KEY"):
        result = await agent.handle("ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ")
        print(f"\nç”¨æˆ·ï¼šä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ")
        print(f"åŠ©æ‰‹ï¼š{result['response']}")
    else:
        print(f"\nâš ï¸  éœ€è¦ OPENAI_API_KEY æ‰èƒ½è¿è¡Œå¯¹è¯ç¤ºä¾‹")
        print(f"ç”¨æˆ·åå­—è®°å¿†ï¼š{agent.retrieve_memory('user_name')}")


async def demo_conversation():
    """æ¼”ç¤ºå¤šè½®å¯¹è¯"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯")
    print("="*60 + "\n")
    
    agent = AINativeAgent(
        name="conversation_partner",
        description="å¯¹è¯ä¼™ä¼´",
        llm_config=LLMConfig(
            provider="openai",
            model="gpt-4",
        ) if os.getenv("OPENAI_API_KEY") else None,
    )
    
    @agent.tool(name="get_weather", description="è·å–å¤©æ°”")
    async def get_weather(city: str) -> dict:
        """è·å–åŸå¸‚å¤©æ°”"""
        # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
        import random
        conditions = ["æ™´", "å¤šäº‘", "å°é›¨", "å¤§é›¨"]
        return {
            "city": city,
            "temperature": random.randint(15, 30),
            "condition": random.choice(conditions),
        }
    
    if os.getenv("OPENAI_API_KEY"):
        # ç¬¬ä¸€è½®å¯¹è¯
        result1 = await agent.handle("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        print(f"ç”¨æˆ·ï¼šåŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        print(f"åŠ©æ‰‹ï¼š{result1['response']}")
        
        # ç¬¬äºŒè½®å¯¹è¯ (æœ‰ä¸Šä¸‹æ–‡)
        result2 = await agent.handle("é‚£ä¸Šæµ·å‘¢ï¼Ÿ")
        print(f"\nç”¨æˆ·ï¼šé‚£ä¸Šæµ·å‘¢ï¼Ÿ")
        print(f"åŠ©æ‰‹ï¼š{result2['response']}")
        
        # ç¬¬ä¸‰è½®å¯¹è¯
        result3 = await agent.handle("æˆ‘åº”è¯¥å¸¦ä¼å—ï¼Ÿ")
        print(f"\nç”¨æˆ·ï¼šæˆ‘åº”è¯¥å¸¦ä¼å—ï¼Ÿ")
        print(f"åŠ©æ‰‹ï¼š{result3['response']}")
    else:
        print("âš ï¸  éœ€è¦ OPENAI_API_KEY æ‰èƒ½è¿è¡Œæ­¤ç¤ºä¾‹")
        
        # æ¼”ç¤ºå·¥å…·è°ƒç”¨
        beijing_weather = await agent.execute_tool("get_weather", city="åŒ—äº¬")
        print(f"åŒ—äº¬å¤©æ°”ï¼š{beijing_weather}")
        
        shanghai_weather = await agent.execute_tool("get_weather", city="ä¸Šæµ·")
        print(f"ä¸Šæµ·å¤©æ°”ï¼š{shanghai_weather}")


async def demo_custom_system_prompt():
    """æ¼”ç¤ºè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 4: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯")
    print("="*60 + "\n")
    
    agent = AINativeAgent(
        name="code_reviewer",
        description="ä»£ç å®¡æŸ¥åŠ©æ‰‹",
        llm_config=LLMConfig(
            provider="openai",
            model="gpt-4",
        ) if os.getenv("OPENAI_API_KEY") else None,
    )
    
    # è®¾ç½®è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
    agent.set_system_prompt("""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯:
1. å®¡æŸ¥ä»£ç è´¨é‡å’Œæœ€ä½³å®è·µ
2. æŒ‡å‡ºæ½œåœ¨çš„é—®é¢˜å’Œ bug
3. æä¾›æ”¹è¿›å»ºè®®
4. ä¿æŒå‹å¥½å’Œå»ºè®¾æ€§çš„è¯­æ°”""")
    
    @agent.tool(name="check_syntax", description="æ£€æŸ¥è¯­æ³•é”™è¯¯")
    async def check_syntax(code: str) -> dict:
        """æ£€æŸ¥ä»£ç è¯­æ³•"""
        try:
            compile(code, '<string>', 'exec')
            return {"valid": True, "errors": []}
        except SyntaxError as e:
            return {"valid": False, "errors": [str(e)]}
    
    if os.getenv("OPENAI_API_KEY"):
        code = """
def calculate_average(numbers):
    total = sum(numbers)
    return total / len(numbers)

result = calculate_average([1, 2, 3, 4, 5])
print(result)
"""
        result = await agent.handle(f"è¯·å®¡æŸ¥è¿™æ®µä»£ç :\n{code}")
        print(f"ç”¨æˆ·ï¼šè¯·å®¡æŸ¥è¿™æ®µä»£ç ")
        print(f"åŠ©æ‰‹ï¼š{result['response']}")
    else:
        print("âš ï¸  éœ€è¦ OPENAI_API_KEY æ‰èƒ½è¿è¡Œæ­¤ç¤ºä¾‹")
        
        code = "print('Hello, World!')"
        syntax_result = await agent.execute_tool("check_syntax", code=code)
        print(f"è¯­æ³•æ£€æŸ¥ï¼š{syntax_result}")


async def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ AI Native Agent é«˜çº§ç¤ºä¾‹")
    print("="*60)
    
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("éƒ¨åˆ†ç¤ºä¾‹å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ")
        print("è®¾ç½®æ–¹æ³•ï¼šexport OPENAI_API_KEY=your-api-key")
        print("="*60)
    
    try:
        await demo_multi_tool()
    except Exception as e:
        print(f"å¤šå·¥å…·åä½œç¤ºä¾‹å¤±è´¥ï¼š{e}")
    
    try:
        await demo_memory()
    except Exception as e:
        print(f"è®°å¿†ç®¡ç†ç¤ºä¾‹å¤±è´¥ï¼š{e}")
    
    try:
        await demo_conversation()
    except Exception as e:
        print(f"å¤šè½®å¯¹è¯ç¤ºä¾‹å¤±è´¥ï¼š{e}")
    
    try:
        await demo_custom_system_prompt()
    except Exception as e:
        print(f"è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ç¤ºä¾‹å¤±è´¥ï¼š{e}")
    
    print("\n" + "="*60)
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    asyncio.run(main())
