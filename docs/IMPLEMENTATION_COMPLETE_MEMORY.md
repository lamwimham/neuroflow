# NeuroFlow v0.5.0 Memory & Knowledge å®ç°æ€»ç»“

**çŠ¶æ€**: âœ… **æ¶æ„å®Œæˆï¼Œä»£ç å¾…é›†æˆ**  
**æ—¥æœŸ**: 2026-03-20

---

## ğŸ“‹ å®ç°æ¦‚è¿°

å·²å®Œæˆ Memory å’Œ Knowledge Extraction çš„å®Œæ•´æ¶æ„è®¾è®¡å’Œæ ¸å¿ƒä»£ç å®ç°ï¼ŒåŒ…æ‹¬ï¼š

1. âœ… **KnowledgeExtractor æ¨¡å—** - ä»å¯¹è¯/æ–‡æ¡£ä¸­æå–çŸ¥è¯†
2. âœ… **ConversationAnalyzer** - è‡ªåŠ¨å¯¹è¯åˆ†æ
3. âœ… **Memory gRPC æœåŠ¡** - ç®€åŒ– HTTP ç‰ˆæœ¬ï¼ˆæ— éœ€ proto ç¼–è¯‘ï¼‰
4. âœ… **Python SDK å®¢æˆ·ç«¯** - å®Œæ•´çš„ gRPC å®¢æˆ·ç«¯
5. âœ… **ä½¿ç”¨ç¤ºä¾‹** - å®Œæ•´çš„ Agent å¯¹è¯ç¤ºä¾‹

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒåŸåˆ™

```
âœ… å•ä¸€èŒè´£ - æ¯ä¸ªæ¨¡å—åšå¥½ä¸€ä»¶äº‹
âœ… ä¾èµ–å€’ç½® - é«˜å±‚ä¸ä¾èµ–ä½å±‚
âœ… æ— å¾ªç¯ä¾èµ– - knowledge â†’ memory + mcp (å•å‘)
âœ… æ˜“äºæµ‹è¯• - å¯ Mock MCP æµ‹è¯• KnowledgeExtractor
```

### æ¨¡å—å…³ç³»

```
knowledge/mod.rs
â”œâ”€â”€ KnowledgeExtractor (æå–çŸ¥è¯†)
â”‚   â”œâ”€â”€ ä¾èµ–ï¼šMemoryManager (å­˜å‚¨)
â”‚   â””â”€â”€ ä¾èµ–ï¼šMCPService (è°ƒç”¨ LLM)
â”‚
â”œâ”€â”€ ConversationAnalyzer (è‡ªåŠ¨åˆ†æ)
â”‚   â””â”€â”€ ä¾èµ–ï¼šKnowledgeExtractor
â”‚
â””â”€â”€ KnowledgeCategory (çŸ¥è¯†åˆ†ç±»)
    â”œâ”€â”€ PersonalInfo
    â”œâ”€â”€ Preference
    â”œâ”€â”€ Skill
    â”œâ”€â”€ Interest
    â””â”€â”€ Fact

grpc/memory_http_service.rs
â”œâ”€â”€ MemoryService (HTTP æœåŠ¡)
â”‚   â”œâ”€â”€ store()
â”‚   â”œâ”€â”€ retrieve()
â”‚   â”œâ”€â”€ search()
â”‚   â”œâ”€â”€ extract_knowledge() â† è°ƒç”¨ KnowledgeExtractor
â”‚   â””â”€â”€ save_conversation()
â”‚
â””â”€â”€ HTTP Routes
    â”œâ”€â”€ POST /api/memory/store
    â”œâ”€â”€ POST /api/memory/retrieve
    â”œâ”€â”€ POST /api/memory/search
    â”œâ”€â”€ POST /api/memory/extract
    â””â”€â”€ POST /api/memory/conversation
```

---

## ğŸ“¦ å·²åˆ›å»ºçš„æ–‡ä»¶

| æ–‡ä»¶ | è¡Œæ•° | çŠ¶æ€ | æè¿° |
|------|------|------|------|
| `kernel/src/knowledge/mod.rs` | 450+ | âœ… | çŸ¥è¯†æå–æ ¸å¿ƒæ¨¡å— |
| `kernel/src/grpc/memory_http_service.rs` | 300+ | âœ… | ç®€åŒ– HTTP æœåŠ¡ |
| `kernel/src/grpc/memory_service.rs` | 450+ | âš ï¸ | å®Œæ•´ gRPC æœåŠ¡ï¼ˆéœ€ protoï¼‰ |
| `sdk/neuroflow/memory/kernel_client.py` | 400+ | âœ… | Python gRPC å®¢æˆ·ç«¯ |
| `sdk/examples/agent_with_memory.py` | 350+ | âœ… | å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ |
| `proto/memory.proto` | 200+ | âœ… | Proto å®šä¹‰ |
| `docs/KNOWLEDGE_EXTRACTION_ARCHITECTURE.md` | 500+ | âœ… | æ¶æ„æ–‡æ¡£ |
| `docs/Memory_CALL_CHAIN.md` | 500+ | âœ… | è°ƒç”¨é“¾è·¯æ–‡æ¡£ |

**æ€»è®¡**: 3150+ è¡Œä»£ç å’Œæ–‡æ¡£

---

## ğŸ”— å®Œæ•´è°ƒç”¨é“¾è·¯

### Python SDK â†’ Rust Kernel

```python
# Python SDK
from neuroflow.memory import KernelMemoryClient

client = KernelMemoryClient(endpoint="localhost:8080")

# æå–çŸ¥è¯†
knowledge = await client.extract_knowledge(
    agent_id="user-123",
    conversation_id="conv-001",
    conversation_text="User: æˆ‘åœ¨åŒ—äº¬å·¥ä½œ...\nAssistant: ...",
)
```

```
è°ƒç”¨é“¾è·¯:
1. Python: KernelMemoryClient.extract_knowledge()
   â†“ (HTTP POST /api/memory/extract)
2. Rust: extract_knowledge handler
   â†“
3. Rust: MemoryService::extract_knowledge()
   â†“
4. Rust: KnowledgeExtractor::extract_from_conversation()
   â”œâ”€â†’ build_extraction_prompt()
   â”œâ”€â†’ MCPService::execute() â†’ LLM (GPT-4)
   â”œâ”€â†’ parse_llm_response()
   â””â”€â†’ MemoryManager::store_memory() Ã— N
       â†“
   InMemoryBackend::store()
       â†“
   HashMap<String, MemoryEntry>
```

---

## ğŸ§  çŸ¥è¯†æå–æµç¨‹

### 1. æ„å»º Prompt

```rust
fn build_extraction_prompt(&self, conversation_text: &str) -> String {
    format!(
        r#"ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–ç”¨æˆ·çš„çŸ¥è¯†ã€‚

å¯¹è¯å†…å®¹:
{conversation}

è¯·æå–ä»¥ä¸‹ç±»å‹çš„çŸ¥è¯†:
1. ä¸ªäººä¿¡æ¯ï¼ˆä½ç½®ã€èŒä¸šã€å…¬å¸ç­‰ï¼‰
2. åå¥½ï¼ˆä¸»é¢˜ã€è¯­è¨€ã€å·¥å…·ç­‰ï¼‰
3. æŠ€èƒ½ï¼ˆç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶ç­‰ï¼‰
4. å…´è¶£ï¼ˆçˆ±å¥½ã€æ´»åŠ¨ç­‰ï¼‰

è¯·ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›...
åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"#,
        conversation = conversation_text
    )
}
```

### 2. è°ƒç”¨ LLM

```rust
async fn call_llm(&self, prompt: &str) -> Result<String> {
    let request = ModelRequest {
        model_name: self.model_name.clone(),  // "gpt-4"
        operation: ModelOperation::Generation,
        parameters: json!({
            "prompt": prompt,
            "max_tokens": 2000,
            "temperature": 0.3,  // ä½æ¸©åº¦ï¼Œæ›´ç¡®å®š
        }),
        ..Default::default()
    };
    
    let response = self.mcp_service.execute(request).await?;
    Ok(response.result.as_str().unwrap_or("").to_string())
}
```

### 3. è§£æè¾“å‡º

```rust
fn parse_llm_response(&self, response: &str) -> Result<Vec<ExtractedKnowledge>> {
    let json_str = response
        .trim()
        .trim_start_matches("```json")
        .trim_end_matches("```")
        .trim();
    
    let items: Vec<ExtractedKnowledge> = serde_json::from_str(json_str)?;
    
    // éªŒè¯å’Œè¿‡æ»¤
    let valid_items = items.into_iter()
        .filter(|item| !item.key.is_empty() && (0.0..=1.0).contains(&item.confidence))
        .collect();
    
    Ok(valid_items)
}
```

### 4. å­˜å‚¨åˆ° Memory

```rust
for item in knowledge_items {
    let entry = MemoryEntry::new(
        agent_id.to_string(),
        format!("knowledge:{}:{}", item.category, item.key),
        json!({
            "value": item.value,
            "confidence": item.confidence,
            "source": "conversation",
        }),
        {
            let mut tags = item.tags.clone();
            tags.push("knowledge".to_string());
            tags.push(item.category.to_string());
            tags
        },
    )
    .with_importance(item.confidence);
    
    self.memory_manager.store_memory(entry).await?;
}
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æ‰‹åŠ¨æå–çŸ¥è¯†

```python
from neuroflow import AINativeAgent
from neuroflow.memory import KernelMemoryClient

agent = AINativeAgent(name="assistant")
memory = KernelMemoryClient(endpoint="http://localhost:8080")

# å¯¹è¯æ–‡æœ¬
conversation = """
User: æˆ‘åœ¨åŒ—äº¬å·¥ä½œï¼Œæ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆ
Assistant: å¾ˆå¥½ï¼æ‚¨ç”¨ä»€ä¹ˆç¼–ç¨‹è¯­è¨€ï¼Ÿ
User: ä¸»è¦ç”¨ Pythonï¼Œå–œæ¬¢ Django å’Œ FastAPI
"""

# æå–çŸ¥è¯†
knowledge = await memory.extract_knowledge(
    agent_id="user-123",
    conversation_id="conv-001",
    conversation_text=conversation,
)

print(f"æå–äº† {len(knowledge)} æ¡çŸ¥è¯†:")
for item in knowledge:
    print(f"  - {item['key']}: {item['value']}")

# è¾“å‡º:
# æå–äº† 3 æ¡çŸ¥è¯†:
#   - user_location: {"city": "åŒ—äº¬", "country": "ä¸­å›½"}
#   - user_profession: {"role": "è½¯ä»¶å·¥ç¨‹å¸ˆ"}
#   - programming_skills: {"languages": ["Python"], "frameworks": ["Django", "FastAPI"]}
```

### ç¤ºä¾‹ 2: è‡ªåŠ¨å¯¹è¯è®°å¿†

```python
from neuroflow.memory import ConversationMemoryManager

memory_mgr = ConversationMemoryManager(
    agent_id="user-123",
    client=KernelMemoryClient(),
)

# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆè‡ªåŠ¨ä¿å­˜ï¼‰
async with memory_mgr.conversation("conv-002") as conv:
    conv.add_user("æˆ‘åœ¨ä¸Šæµ·å·¥ä½œ")
    response = await agent.chat("æˆ‘åœ¨ä¸Šæµ·å·¥ä½œ")
    conv.add_assistant(response)
    
    conv.add_user("æˆ‘å–œæ¬¢ç”¨ Python ç¼–ç¨‹")
    response = await agent.chat("æˆ‘å–œæ¬¢ç”¨ Python ç¼–ç¨‹")
    conv.add_assistant(response)
    
    conv.add_user("å¹³æ—¶å–œæ¬¢æ‰“ç¯®çƒ")
    response = await agent.chat("å¹³æ—¶å–œæ¬¢æ‰“ç¯®çƒ")
    conv.add_assistant(response)

# é€€å‡ºæ—¶è‡ªåŠ¨:
# 1. ä¿å­˜å¯¹è¯
# 2. æå–çŸ¥è¯†ï¼ˆè¾¾åˆ° 3 è½®æœ€å°è½®æ•°ï¼‰
# 3. å­˜å‚¨åˆ° Memory
```

### ç¤ºä¾‹ 3: æœç´¢çŸ¥è¯†

```python
# æœç´¢æŠ€èƒ½ç›¸å…³
skills = await memory.search(
    agent_id="user-123",
    tags=["skill"],
    min_importance=0.8,
    limit=10,
)

# æœç´¢ä¸ªäººä¿¡æ¯
personal = await memory.search(
    agent_id="user-123",
    tags=["personal_info"],
    limit=5,
)

# è¯­ä¹‰æœç´¢ï¼ˆéœ€è¦å®ç°ï¼‰
memories = await memory.semantic_search(
    agent_id="user-123",
    query_text="ç”¨æˆ·çš„å·¥ä½œå’ŒæŠ€æœ¯æ ˆ",
    top_k=5,
)
```

---

## âš ï¸ å¾…å®Œæˆçš„å·¥ä½œ

### 1. Rust ä»£ç é›†æˆ

éœ€è¦æ›´æ–° `kernel/src/main.rs` æ¥æ³¨å†Œ Memory æœåŠ¡ï¼š

```rust
// kernel/src/main.rs
use kernel::grpc::{MemoryService, configure_memory_routes};
use kernel::memory::{MemoryManager, InMemoryBackend, MemoryConfig};
use kernel::mcp::MCPService;

async fn run_server(args: ServerArgs) -> Result<(), Box<dyn std::error::Error>> {
    // ... ç°æœ‰ä»£ç  ...
    
    // åˆå§‹åŒ– Memory
    let memory_config = MemoryConfig::default();
    let memory_manager = Arc::new(MemoryManager::new(
        Arc::new(InMemoryBackend::new(memory_config)),
        memory_config,
    ));
    
    // åˆå§‹åŒ– MCP
    let mcp_service = Arc::new(MCPService::new(MCPConfig::default()));
    
    // åˆ›å»º Memory æœåŠ¡ï¼ˆå¸¦ Knowledge Extractorï¼‰
    let memory_service = Arc::new(
        MemoryService::new(memory_manager.clone())
            .with_knowledge_extractor(mcp_service.clone())
    );
    
    // é…ç½® HTTP è·¯ç”±
    let app = App::new()
        .app_data(web::Data::new(memory_service))
        .configure(configure_memory_routes)
        // ... å…¶ä»–è·¯ç”± ...
    
    // å¯åŠ¨ HTTP æœåŠ¡å™¨
    HttpServer::new(move || app.clone())
        .bind(("0.0.0.0", config.server.port))?
        .run()
        .await
}
```

### 2. Proto ç¼–è¯‘ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦å®Œæ•´çš„ gRPC æ”¯æŒï¼š

```bash
# å®‰è£… protoc
brew install protoc  # macOS
# æˆ–
apt-get install protobuf-compiler  # Linux

# ç¼–è¯‘ proto
cd proto
protoc --rust_out=../kernel/src/proto \
       --python_out=../sdk/neuroflow/proto \
       --grpc_python_out=../sdk/neuroflow/proto \
       memory.proto
```

### 3. Python SDK Proto æ–‡ä»¶

éœ€è¦ç¼–è¯‘ proto æ–‡ä»¶ç”Ÿæˆ Python gRPC ä»£ç ï¼š

```bash
cd sdk
python -m grpc_tools.protoc \
  -I../proto \
  --python_out=neuroflow/proto \
  --grpc_python_out=neuroflow/proto \
  ../proto/memory.proto
```

---

## ğŸ¯ æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•

```rust
// kernel/src/knowledge/mod.rs
#[cfg(test)]
mod tests {
    #[test]
    fn test_knowledge_category_display() {
        assert_eq!(KnowledgeCategory::PersonalInfo.to_string(), "personal_info");
    }
    
    #[test]
    fn test_parse_empty_response() {
        let extractor = KnowledgeExtractor::new(...);
        let result = extractor.parse_llm_response("[]");
        assert!(result.is_ok());
        assert!(result.unwrap().is_empty());
    }
}
```

### é›†æˆæµ‹è¯•

```python
# sdk/tests/memory/test_kernel_client.py
async def test_extract_knowledge():
    client = KernelMemoryClient(endpoint="http://localhost:8080")
    
    conversation = """
    User: æˆ‘åœ¨åŒ—äº¬å·¥ä½œ
    Assistant: å¾ˆå¥½ï¼
    User: æˆ‘æ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆ
    """
    
    knowledge = await client.extract_knowledge(
        agent_id="test-user",
        conversation_id="test-conv",
        conversation_text=conversation,
    )
    
    assert len(knowledge) > 0
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡ï¼ˆç›®æ ‡ï¼‰

| æ“ä½œ | å»¶è¿Ÿ (P50) | å»¶è¿Ÿ (P99) | è¯´æ˜ |
|------|------------|------------|------|
| extract_knowledge | ~2s | ~5s | åŒ…å« LLM è°ƒç”¨ |
| save_conversation (10 turns) | ~50ms | ~200ms | çº¯å­˜å‚¨ |
| search_memories | ~5ms | ~20ms | å†…å­˜æœç´¢ |
| retrieve_memory | ~1ms | ~5ms | HashMap æŸ¥æ‰¾ |

---

## ğŸ”’ å®‰å…¨è€ƒè™‘

1. **Prompt æ³¨å…¥é˜²æŠ¤**
   - è¿‡æ»¤ç”¨æˆ·è¾“å…¥
   - é™åˆ¶ prompt é•¿åº¦
   - éªŒè¯ LLM è¾“å‡ºæ ¼å¼

2. **æ•°æ®éšç§**
   - æ•æ„Ÿä¿¡æ¯åŠ å¯†
   - è®¿é—®æ§åˆ¶
   - å®¡è®¡æ—¥å¿—

3. **ç½®ä¿¡åº¦é˜ˆå€¼**
   - ä½ç½®ä¿¡åº¦éœ€è¦äººå·¥å®¡æ ¸
   - å¯é…ç½®æœ€å°ç½®ä¿¡åº¦

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Knowledge Extraction Architecture](KNOWLEDGE_EXTRACTION_ARCHITECTURE.md)
- [Memory Call Chain](Memory_CALL_CHAIN.md)
- [Security Whitepaper](SECURITY_WHITEPAPER_v0.5.0.md)
- [Release Notes](RELEASE_NOTES_v0.5.0.md)

---

**å®ç°çŠ¶æ€**: æ¶æ„å®Œæˆ âœ…ï¼Œæ ¸å¿ƒä»£ç å®Œæˆ âœ…ï¼Œå¾…é›†æˆ â³

*Last updated: 2026-03-20*
