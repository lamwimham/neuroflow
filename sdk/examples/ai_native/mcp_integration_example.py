"""
MCP (Model Context Protocol) é›†æˆç¤ºä¾‹

å±•ç¤ºå¦‚ä½•é›†æˆ MCP æœåŠ¡:
1. å‘ç° MCP å·¥å…·
2. è°ƒç”¨ MCP å·¥å…·
3. ç»“åˆæœ¬åœ°å·¥å…·å’Œ MCP å·¥å…·

è¿è¡Œ:
    python examples/ai_native/mcp_integration_example.py
"""

import asyncio
import os
from neuroflow import AINativeAgent, LLMConfig, MCPToolExecutor, UnifiedToolRegistry, ToolSource


async def demo_mcp_discovery():
    """æ¼”ç¤º MCP å·¥å…·å‘ç°"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 1: MCP å·¥å…·å‘ç°")
    print("="*60 + "\n")
    
    # åˆ›å»º MCP æ‰§è¡Œå™¨
    mcp_executor = MCPToolExecutor(
        mcp_endpoint=os.getenv("MCP_ENDPOINT", "http://localhost:8081")
    )
    
    print(f"MCP æœåŠ¡ç«¯ç‚¹ï¼š{mcp_executor._mcp_endpoint}")
    
    # å°è¯•å‘ç°å·¥å…·
    try:
        tools = await mcp_executor.discover_tools()
        print(f"å‘ç° {len(tools)} ä¸ª MCP å·¥å…·:")
        for tool in tools:
            print(f"  - {tool.name}: {tool.description}")
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è¿æ¥åˆ° MCP æœåŠ¡å™¨ï¼š{e}")
        print("è¯·ç¡®ä¿ MCP æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")
        
        # åˆ›å»ºæ¨¡æ‹Ÿå·¥å…·ç”¨äºæ¼”ç¤º
        from neuroflow import ToolDefinition, ToolParameter
        
        mock_tools = [
            ToolDefinition(
                id="mcp:embedding",
                name="get_embeddings",
                description="è·å–æ–‡æœ¬åµŒå…¥å‘é‡",
                source=ToolSource.MCP_SERVER,
                parameters=[
                    ToolParameter(
                        name="texts",
                        parameter_type="array",
                        description="æ–‡æœ¬åˆ—è¡¨",
                        required=True,
                    ),
                    ToolParameter(
                        name="model",
                        parameter_type="string",
                        description="åµŒå…¥æ¨¡å‹",
                        required=False,
                        default_value="sentence-transformers/all-MiniLM-L6-v2",
                    ),
                ],
                metadata={"server_url": "http://localhost:8081"},
            ),
            ToolDefinition(
                id="mcp:generate",
                name="generate_text",
                description="ç”Ÿæˆæ–‡æœ¬",
                source=ToolSource.MCP_SERVER,
                parameters=[
                    ToolParameter(
                        name="prompt",
                        parameter_type="string",
                        description="æç¤ºè¯",
                        required=True,
                    ),
                    ToolParameter(
                        name="max_length",
                        parameter_type="number",
                        description="æœ€å¤§é•¿åº¦",
                        required=False,
                        default_value=100,
                    ),
                ],
                metadata={"server_url": "http://localhost:8081"},
            ),
        ]
        
        print(f"\nä½¿ç”¨ {len(mock_tools)} ä¸ªæ¨¡æ‹Ÿ MCP å·¥å…·è¿›è¡Œæ¼”ç¤º:")
        for tool in mock_tools:
            print(f"  - {tool.name}: {tool.description}")
        
        return mock_tools
    
    return tools


async def demo_mixed_tools():
    """æ¼”ç¤ºæ··åˆä½¿ç”¨æœ¬åœ°å·¥å…·å’Œ MCP å·¥å…·"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 2: æ··åˆå·¥å…·ä½¿ç”¨")
    print("="*60 + "\n")
    
    # åˆ›å»º Agent
    agent = AINativeAgent(
        name="hybrid_assistant",
        description="æ··åˆåŠ©æ‰‹",
        llm_config=LLMConfig(
            provider="openai",
            model="gpt-4",
        ) if os.getenv("OPENAI_API_KEY") else None,
    )
    
    # æ³¨å†Œæœ¬åœ°å·¥å…·
    @agent.tool(name="process_locally", description="æœ¬åœ°å¤„ç†æ•°æ®")
    async def process_locally(data: str) -> dict:
        """æœ¬åœ°æ•°æ®å¤„ç†"""
        return {
            "processed": True,
            "length": len(data),
            "uppercase": data.upper(),
        }
    
    # å°è¯•æ·»åŠ  MCP å·¥å…·
    mcp_tools = await demo_mcp_discovery()
    
    # æ‰‹åŠ¨æ³¨å†Œæ¨¡æ‹Ÿ MCP å·¥å…·åˆ°æ³¨å†Œè¡¨
    for tool_def in mcp_tools:
        agent.tool_registry.register_tool(tool_def)
    
    print(f"\næ€»å¯ç”¨å·¥å…·ï¼š{agent.list_available_tools()}")
    
    if os.getenv("OPENAI_API_KEY"):
        # æµ‹è¯•ï¼šè®© LLM å†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·
        result = await agent.handle(
            "è¯·å¤„ç†è¿™æ®µæ–‡æœ¬ï¼š'Hello World'"
        )
        print(f"\nç”¨æˆ·ï¼šè¯·å¤„ç†è¿™æ®µæ–‡æœ¬ï¼š'Hello World'")
        print(f"åŠ©æ‰‹ï¼š{result['response']}")
        print(f"ä½¿ç”¨çš„å·¥å…·ï¼š{len(result['tool_results'])} ä¸ª")
    else:
        print("\nâš ï¸  éœ€è¦ OPENAI_API_KEY æ‰èƒ½è¿è¡Œå®Œæ•´ç¤ºä¾‹")
        
        # æ¼”ç¤ºæœ¬åœ°å·¥å…·è°ƒç”¨
        result = await agent.execute_tool("process_locally", data="Hello World")
        print(f"\næœ¬åœ°å·¥å…·ç»“æœï¼š{result}")


async def demo_mcp_embedding():
    """æ¼”ç¤º MCP åµŒå…¥æœåŠ¡"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 3: æ–‡æœ¬åµŒå…¥")
    print("="*60 + "\n")
    
    # åˆ›å»º Agent
    agent = AINativeAgent(
        name="embedding_assistant",
        description="åµŒå…¥åŠ©æ‰‹",
    )
    
    # æ·»åŠ æ¨¡æ‹ŸåµŒå…¥å·¥å…·
    @agent.tool(name="embed_texts", description="å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡")
    async def embed_texts(texts: list, model: str = "demo") -> list:
        """æ¨¡æ‹Ÿæ–‡æœ¬åµŒå…¥"""
        import random
        # ç”Ÿæˆéšæœºå‘é‡ (æ¨¡æ‹Ÿ)
        return [
            [random.random() for _ in range(128)]
            for _ in texts
        ]
    
    @agent.tool(name="calculate_similarity", description="è®¡ç®—å‘é‡ç›¸ä¼¼åº¦")
    async def calculate_similarity(vec1: list, vec2: list) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = sum(a * a for a in vec1) ** 0.5
        norm2 = sum(b * b for b in vec2) ** 0.5
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return dot_product / (norm1 * norm2)
    
    # æµ‹è¯•
    texts = ["Hello World", "Hi there", "Goodbye"]
    
    print(f"æ–‡æœ¬ï¼š{texts}")
    
    embeddings = await agent.execute_tool("embed_texts", texts=texts)
    print(f"\nç”Ÿæˆçš„åµŒå…¥å‘é‡ï¼š{len(embeddings)} ä¸ª")
    print(f"æ¯ä¸ªå‘é‡ç»´åº¦ï¼š{len(embeddings[0])}")
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    similarity = await agent.execute_tool(
        "calculate_similarity",
        vec1=embeddings[0],
        vec2=embeddings[1]
    )
    print(f"\n'Hello World' å’Œ 'Hi there' çš„ç›¸ä¼¼åº¦ï¼š{similarity:.4f}")
    
    similarity2 = await agent.execute_tool(
        "calculate_similarity",
        vec1=embeddings[0],
        vec2=embeddings[2]
    )
    print(f"'Hello World' å’Œ 'Goodbye' çš„ç›¸ä¼¼åº¦ï¼š{similarity2:.4f}")


async def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸ”Œ MCP é›†æˆç¤ºä¾‹")
    print("="*60)
    
    if not os.getenv("MCP_ENDPOINT"):
        print("âš ï¸  æœªè®¾ç½® MCP_ENDPOINT ç¯å¢ƒå˜é‡")
        print("ä½¿ç”¨é»˜è®¤ç«¯ç‚¹ï¼šhttp://localhost:8081")
        print("è®¾ç½®æ–¹æ³•ï¼šexport MCP_ENDPOINT=http://your-mcp-server:8081")
        print("="*60)
    
    try:
        await demo_mcp_discovery()
    except Exception as e:
        print(f"MCP å‘ç°ç¤ºä¾‹å¤±è´¥ï¼š{e}")
    
    try:
        await demo_mixed_tools()
    except Exception as e:
        print(f"æ··åˆå·¥å…·ç¤ºä¾‹å¤±è´¥ï¼š{e}")
    
    try:
        await demo_mcp_embedding()
    except Exception as e:
        print(f"åµŒå…¥ç¤ºä¾‹å¤±è´¥ï¼š{e}")
    
    print("\n" + "="*60)
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    asyncio.run(main())
